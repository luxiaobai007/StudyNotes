[toc]



**程序=数据结构+算法**

# 数据结构

数据结构是指**逻辑意义**上的数据**组织方式**及其相应**处理方式**

### 逻辑意义

数据结构的一种抽象表达,比如二叉树,它在磁盘中的存储形式并非树形排列.实际上它是基于物理上的一种顺序存储方式.

可以理解为一个格子一个格子连续的放,然后第一个格子放根节点,第二个格子放左子树根节点,并且根据引用知道左叶子在后续那个格子里;第三个格子放右子树根节点,依次类推.

### 数据组织方式

- 树:二叉树、三叉树、B+树等
- 图:有向图、无向图
- 队列: 先进先出的线性结构
- 哈希: 根据某种算法直接定位的数据组织方式



### 数据处理方式

在既定的数据组织方式上,以某种特定的算法实现数据的CRUD和遍历.



## 数据结构分类

从直接前趋和直接后继个数的维度来看.

### 线性结构

0至1个直接前趋和直接后继.当线性结构非空的时候,有唯一的首元素和尾元素,除两者外,其他元素都有唯一的直接前趋和直接后继.

线性结构包括: 顺序表、链表、栈、队列等;

其中栈和队列都是访问受限的结构.

栈是后进先出的,即Last-In,First-Out,LIFO.

队列是先进先出的,即First-In,First-Out.FIFO.



### 树结构

0至1个直接前趋和0至n个直接后继(n大于或等于2).树是一种非常重要的有层次的非线性结构.



### 图结构

0至n个直接前趋和直接后继(n大于或等于2). 图结构包括:简单图、多重图、有向图和无向图等.



### 哈希结构

没有直接前趋和直接后继,是根据某种特定的哈希函数将索引与存储的值关联起来,是一种查找效率非常高的数据结构.





### 复杂度

如何衡量数据处理的性能.

数据结构的复杂度分为**空间复杂度** 和**时间复杂度.**

算法时间复杂度是一种衡量计算机性能的指标,反映了程序执行时间随输入规模增长而增长的量级,在很大程度上反映算法性能的优劣

最好到最差的常用算法复杂度排序:常数级O(1)、对数级O(logn)、线性级O(n)、线性对数级O(nlogn)、平方级O(n^2^)、立方级O(n^3^)、指数级O(2^n^)

二分查找 时间复杂度O(logn)

优秀的程序实现不会因为数据规模的急剧上升导致程序性能的急剧下降



>数据结构的各种类型没有好坏之分,只有与场景、数据量结合起来进行综合考虑
>
>场景包括:操作类型及其频率,数据量大小决定它选择什么样的数据结构类型.到底是写为主,还是读为主,或者读写均衡.



# 集合

具有某种特点性质的事物汇成的集体

集合作为数据结构的载体,可对元素进行加工和输出,以一定的算法实现的增删改查

- 确定性

- 无序性

- 互异性

  

## 集合框架图

![](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210903153053377.png)

红色表示接口、蓝色代表抽象类、绿色代表并发包中的类、灰色代表早期线程安全的类(基本已经弃用).



## List集合

List集合是线性数据结构的主要实现,集合元素通常存在明确的上一个和下一个元素,也存在明确的第一个和最后一个元素.

List集合遍历是稳定的.

### ArrayList

容量是可以改变的非线程安全集合.

集合扩容时会创建更大的数组空间,把原有数据复制到新数组中.ArrayList支持快速随机访问,但是插入和删除时很慢,需要移动其他元素.

### LinkedList

本质是双向链表.与Array List相比,插入与删除速度更快,但是随机访问速度很慢.

它继承了Abstract List抽象类外,还实现了另一个接`Deque`,即`double-ended queue`.这个接口同时具有栈和队列的性质

#### LinkedList成员:

- size:双向链表中节点的个数
- first:第一个节点的引用
- last:最后一个节点的引用

#### 优点

可以将临散的内存单元,通过附加引用的方式关联起来,形成按链路顺序查找的线性结构,内存利用率高



## Queue集合

一种先进先出的数据结构,队列是一种特殊的线性表,只允许在表的一端进行获取操作,另一端进行插入操作.当队列中没有元素时,就是空队列.



## Map集合

是以Key-Value键值对进行存储元素.

Key是根据哈希函数进行计算,是唯一的,而Value是可以重复的.

keySet()查看所有的Key;

values()查看所有的Value;

entrySet()查看所有的键值对

TreeMap是key有序的Map类集合

## Set集合

不允许出现重复元素的集合类型.常用的是HashSet、TreeSet和LinkedHashSet三个集合类

HashSet从源码分析是使用HashMap来实现的,Value为固定的一个静态对象,是Key来保证集合元素的唯一性.不保证元素的顺序

TreeSet也是类似,使用TreeMap来实现的,底层为树结构

LinkeHashSet继承自HashSet,内部使用链表维护了元素插入顺序.

```java
private static final Object PRESENT = new Object();

    /**
     * Constructs a new, empty set; the backing <tt>HashMap</tt> instance has
     * default initial capacity (16) and load factor (0.75).
     */
    public HashSet() {
        map = new HashMap<>();
    } 

		public boolean add(E e) {
        return map.put(e, PRESENT)==null;
    }
```



# 集合初始化

集合初始化通常进行分配容量、设置特定参数等相关工作.以ArrayList和HashMap为例

### ArrayList

```java
public class ArrayList<E> extends AbstractList<E> implements List<E>, RandomAccess, Cloneable, java.io.Serializable {
  pirvate static final int DEFAULT_CAPACITY = 10;
  //空表的表示方法
  private static final Object[] EMPTY_ELEMENTDATA = {};
  transient Object[] elementData;
  private int size;
  
  public ArrayList(int initialCapacity){
    if(initialCapacity > 0){
      //值大于0时,根据构造方法的参数值,忠实地创建一个多大的数组
      this.elementData = new Object[initialCapacity];
    }else if(initialCapacity == 0){
      this.elementData = EMPTY_ELEMENTDATA;
    }
  }
  
  //公开的add方法调用此内部私有方法
  private void add(E e, Object[] elementData, int s){
    //当前数组能容纳size+1 的元素,如果不够,则调用grow来扩容
    if(s == elementData.length)
      elementData = grow();
    elementData[s] = e;
    size = s + 1;
  }
  
  private Object[] grow(){
    return grow(size + 1);
  }
  
  ///扩容的最小要求,必须容纳刚才的元素个数+1,注意newCapacity()方法才是扩容的重点
  private Object[] grow(init minCapacity){
    return elementData = Arrays.copyOf(elementData,newCapacity(minCapacity));
  }
  
  private int new Capacity(int minCapacity){
    //防止扩容1.5倍之后,超过int的表示范围
    int oldCapacity = elementData.length;
    //JDK6之前扩容50%或50%-1,但是取ceil,而之后的版本取floor
    int newCapacity = oldCapacity + (oldCapacity >> 1); //设置新的存储能力为原来的1.5倍
    if(newCapacity - minCapacity <= 0){
      if(elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA){
        //无参数构造方法,会在此时分配默认为10的容量
        return Math.max(DEFAULT_CAPACITY, minCapacity);
      }
      if(minCapacity < 0)
        throw new OutOfMemoryError();
      return minCapacity;
    }
    return (newCapacity-MAX_ARRAY_SIZE <= 0) ? new Capacity : hugeCapacity(minCapacity);
  }
}
```

当ArrayList使用无参构造时,默认大小为10,在第一次add时,分配10的容量,后续的每次扩容都会调用Array.copyof方法,创建新数组在复制.

假设需要将1000个元素放置在ArrayList中,采用默认构造方法,则需要扩容13次(**每次扩容为原来的1.5倍**)才可以完成存储.,如果在初始化便指定来容量new ArrayList(1000),从而避免被动扩容和数组复制的额外开销.



### HashMap

如果需要放置1000个元素,没有设置初始容量大小,则需要被动扩容7次,才可以完成存储.扩容时需要重建hash表,非常影响性能.

Capacity:存储容量的大小,默认为16

Load Factor: 决定了填充比例,一般使用默认的0.75.

```java
public V put(K key, V value){
  if(table == EMPTY_TABLE{
    inflateTable(threshold);
  })
    ....
}

//第一次put时,调用如下方法,初始化table
private void inflateTable(int toSize){
  //找到大于参数值且最接近2的幂值,假如输入参数是27,则返回32
  int capacity = roundUpToPowerOf2(toSize);
  
  //threshold在不超过限制最大值的前提下等于capacity* loadFactor
  threshold = (int)Math.min(capacity 8 loadFactor, MAXIMUM_CAPACITY +1);
  table = new Entry[capacity];
  initHashSeedAsNeeded(capacity);
}
```



在初始化时合理设置容量大小,避免不断扩容带来的性能损耗,如果暂时无法确定集合大小,指定相应的默认值.



# 数组与集合

数组是一种顺序表,可以使用索引下标进行快速定位并获取指定位置的元素.

下标从0开始,源于BCPL语言,它将指针设置在0的位置,用数组下标作为直接偏移量进行计算.计算偏移量就要使用当前下标减一的操作.加减法运算对CPU来说是一个双数运算,在数组下标使用频率极高的场景下,这种运算非常耗时.

### 数组

数组用以存储同一类型的对象,一旦分配内存后则无法扩容.

```java
String[] args = {"a","b"};
//数组引用赋值给Object
Object obj = args;
//使用类名String[] 进行强制转化,并成功赋值,args[0]的值由a变为object
((String[]) obj)[0] = "object"
```



声明数组和赋值

```java
String[] args3 = {"a","b"};
String[] args4 = new String[2]; //如果写负数,并不会编译出差,但运行时会抛出异常: NegativeArraySizeException.
args4[0] = "a";
args4[1] = "b";
```



### 数组遍历

优先推荐`foreach`方式,即`for(元素:数组名)`的方式,可以在不使用下标的情况下遍历数组.如果需要使用下标,则使用`for(int i = 0; i< array.length;i++)`的方式.也可以使用JDK8的函数式接口遍历

```java
Arrays.asList(args3).stream().forEach(x -> System.out.println(x));
Arrays.asList(args4).stream().forEach(System.out::println);
```



#### Arrays

针对数组对象进行操作的工具类,如数组的排序、查找、对比、拷贝等操作,也可以把数组转成集合.

##### 数组转集合

如Arrays.asList(),将数组转成集合时,不能使用其修改集合相关的方法,它的`add/remove/clear`方法会抛出`UnsupportedOperationException`异常.

Arrays.asList()体现的是适配器模式时,后台的数据还是原有数组,asList的返回对象是一个Arrays的内部类,它并没有实现集合个数的相关修改方法.而异常是由这个内部类(ArrayList)的父类(AbstractList)抛出的.



##### 集合转数组

```java
public class ListToArray {
    public static void main(String[] args) {
        ArrayList<String> list = new ArrayList<>(3);
        list.add("one");
        list.add("two");
        list.add("three");

        //泛型丢失，无法使用String[]接收无参方法返回的结果  //1
        Object[] array1 = list.toArray();

        String[] array2 = new String[2];
        list.toArray(array2);
        System.out.println(Arrays.asList(array2));//2

        String[] array3 = new String[3];
        list.toArray(array3);
        System.out.println(Arrays.asList(array3));//3

    }
}
[null, null]
[one, two, three]
```

  第1处,不要用toArray()无参方法把集合转换成数组,会到导致泛型丢失

第2处与第3处在于数组容量是否足够,不够,则弃用此数组.



```java
public class ToArray {
    private static final int COUNT = 100 * 100 * 100;
    public static void main(String[] args){
        List<Double> list = new ArrayList<>(COUNT);
        //构造100个元素的测试集合
        for (int i = 0; i < COUNT; i++) {
            list.add(i * 1.0);
        }

        long start = System.nanoTime();

        Double[] notEnoughArray = new Double[COUNT - 1];
        list.toArray(notEnoughArray);

        long middle1 = System.nanoTime();

        Double[] equalArray = new Double[COUNT];
        list.toArray(equalArray);

        long middle2 = System.nanoTime();
        Double[] doubleArray = new Double[COUNT *2];
        list.toArray(doubleArray);
        long end = System.nanoTime();
        long nodeEnoughTime = middle1 = start;
        long equalArrayTime = middle2 - middle1;
        long doubleTime = end - middle2;
        System.out.println("小于：" + nodeEnoughTime);
        System.out.println("等于：" + equalArrayTime);
        System.out.println("大于：" + doubleTime);
    }
}
小于：788326783023
等于：36420284
大于：5462270
```

测试: 具体的执行时间,由于CPU资源占有的随机性,会有一定差异.多次结果显示,当数组容量等于集合大小时,运行总是最快的,空间消耗也是最小的.



# 集合与泛型

泛型: 参数化类型,指定的不同类型来控制形参具体限制的类型

## 泛型优点

能够在编译时而不是在运行时检测出错误.

```java
public class ListNoGeneric {
    public static void main(String[] args) {
        //，泛型出现之前的集合定义方式
        List a1 = new ArrayList();
        a1.add(new Object());
        a1.add(new Integer(111));
        a1.add(new String("hello,a1"));
        
        //a1引用赋值给a2，注意a2与a1 的区别是增加了泛型限制<Object>
        List<Object> a2 = a1;
        a2.add(new Object());
        a2.add(new Integer(222));
        a2.add(new String("hello,a2"));
        
        //a1引用赋值给a3， a3与a1的区别是增加了泛型<Integer>
        List<Integer> a3 = a1;
        a3.add(new Integer(333));
        //编译错误，不允许增加非Integer类型进入集合
        a3.add(new Object());
        a3.add(new String("hello,a3"));
        
        //a1赋值给a4，区别增加了通配符
        List<?> a4 = a1;
        //允许删除和清除元素
        a4.remove(0);
        a4.clear();
        //编译出错，不允许增加任何元素
        a4.add(new Object());
    }
}
```



## <? extends T>

可以赋值给任何T及其T的子类

无法进行add操作,除null外,任何元素都不能被添加进<? extends T>集合内.

## <? super T>

可以赋值给任何T及其T的父类,取数据时,容易造成泛型丢失





## hashCode和equals

生成的哈希将数据离散开来,可以使存取元素更快.

当hashCode相同时,发生哈希冲突,则在调用equals进行一次值的比较;

若hashCode不同时,将直接判定Objects不同,跳过equals



### 要求

1. 如果两个对象的equals的结果是相等的,则两个对象的hashCode的返回结果也必须是相同的
2. 任何时候复写equals,都必须覆写hashCode.



# Map集合

Map类就是使用一定的哈希算法形成一组比较均匀的哈希值作为Key,Value值挂在Key上.

## 特点

- Map类取代了旧的抽象类Dictionary,拥有更好的性能
- 没有重复的key,可以有多个重复的value
- Value可以是List、Map、Set类对象
- KV是否允许为null,以实现类约束为准

Map接口除传统的增删改查方式外,还有三个Map类特有的方法

```java
//返回Key的Set视图
Set<K> keySet();

//返回Map类对象中的所有Value集合的Collection视图
//返回的集合实现类为Values extends AbstractCollection<V>
Collection<V> values();

//返回Map类对象中的Key-Value对的Set视图
Set<Map.Entry<K,V>> entrySet();
```

这些返回的视图是支持清除操作的,但是修改和增加元素会抛出异常,因为AbstractCollection没有实现add操作,但是实现了remove、clear等相关操作.



### KV是否为null,的实现类约束

|     Map集合类     |     Key      |    Value     |    Super    | JDK  |            说明             |
| :---------------: | :----------: | :----------: | :---------: | :--: | :-------------------------: |
|     Hashtable     | 不允许为null | 不允许为null | Dictionary  | 1.0  |       线程安全(过时)        |
| ConcurrentHashMap | 不允许为null | 不允许为null | AbstractMap | 1.5  | 锁分段技术或CAS(JDK8及以上) |
|      TreeMap      | 不允许为null |  允许为null  | AbstractMap | 1.2  |      线程不安全(有序)       |
|      HashMap      |  允许为null  |  允许为null  | AbstractMap | 1.2  | 线程不安全(resize死链问题)  |







# 红黑树

## 树

是一个由有限节点组成的一个具有层次关系的集合.

![image-20210904135617907](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210904135617907.png)

root是根节点.

如果某个节点下方没有任何分叉的话,就是叶子节点.

从某节点出发,到叶子结点为止,最长简单路径上边的条数就是该结点的**高度**

从根节点出发,到某节点的条数,称该节点的**深度**

**度指的是一个节点拥有子节点的个数。如二叉树的节点的最大度为2。**

如,root的高度是5,深度是0; 2的高度是4,深度是1;



### 特点

1. 一个节点,即只有根节点,也可以是一棵树
2. 其中任何一个节点与下面所有节点构成的树称为子树
3. 根节点没有父节点,而叶子节点没有子节点
4. 除根节点外,任何节点有且仅有一个父节点
5. 任何节点可以有0~n个子节点



### 二叉树

每个节点至多有两个子节点的树称为二叉树.如上图所示就是二叉树.

二叉树是近似于二分法的一种数据结构实现.



## 平衡二叉树

![image-20210904142445021](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210904142445021.png)

高度差是一棵树是否为平衡二叉树的决定条件

### 性质

1. 树的左右高度差不能超过1
2. 任何往下递归的左子树与右子树,必须符合第一条性质
3. 没有任何节点的空树或只有根节点的树也是平衡二叉树



## 二叉查找树

二叉查找树也称为二叉搜索树,即Binary Search Tree, 其中也可以替换为Sort,所以也称为二叉排序树.

### 二叉树额外增加了如下要求

- 任意节点来说,
  - 它的左子树上所有节点的值都小于它
  - 而它的右子树上所有节点的值都大于它.



### 查找过程

沿着简单的判断往下走,小于节点值的往左边走,大于节点值的往右边走,直到找到目标数据或者到达叶子节点还未找到.



### 遍历方式

#### 前序遍历: 根节点、左节点、右节点

#### 中序遍历: 左节点、根节点、右节点

#### 后序遍历:左节点、右节点、根节点

>规律:
>
>1. 在任何递归子树中,左节点一定在右节点之前先遍历
>2. 前序、中序、后序,仅指根节点在遍历时的位置顺序

![image-20210904143834533](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210904143834533.png)

​																												中序遍历

#### 转换二叉查找树

![image-20210904150000895](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210904150000895.png)

二叉查找树随着数据不断地增加或删除容易失衡.





## AVL树

AVL树算法可以使二叉树的使用效率最大化.

AVL树是一种平衡二叉查找树,增加和删除节点后通过**树形旋转**重新达到平衡.

### 右旋

- 右旋是以某个节点为中心,将它沉入当前右子节点的位置,而让当前的左子节点作为新树的根节点,也称为顺时针旋转.

  在仅有三个节点时,非常简单,但是当**15**存在右节点时,通常是抛弃右节点,将之和旋转后的**17**相连,称为**17**的左节点

  ![image-20210904152715084](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210904152715084.png)

  ### 左旋

- 左旋是以某个节点为中心,将它沉入当前左子节点的位置,而让当前的右子节点作为新树的根节点,也称为逆时针旋转.

![image-20210904153653172](/Users/lushengyang/Library/Application Support/typora-user-images/image-20210904153653172.png)



## 红黑树

### 主要特征

在每个节点上增加一个属性来表示节点的颜色,可以是红色,也可以是黑色.

红黑树和AVL树类似,都是在进行插入和删除元素时,通过特定的旋转来保持自身平衡的,从而获得较高的查找性能.

与AVL树相比,红黑树并不追求所有递归子树的高度差不差过1,而是保证**从根节点到叶尾的最长路径不超过最短路径的2倍**,所以它的最坏运行时间**O(logn)**.

红黑树通过**重新着色和左右旋转**,更加高效地完成了插入和删除操作后的自平衡操作.本质上还是二叉查找树.

### 约束条件

1. 节点只能是红色或黑色
2. 根节点必须是黑色
3. 所有NIL节点都是黑色
4. 一条路径上不能出现相邻的两个红色节点.(每个红色节点必须有两个黑色的子节点)
5. 在任何递归子树内,根节点到叶子节点的所有路径上包含相同数目的黑色节点

>NIL: Nothing In Leaf,是红黑树中特殊的存在,即在叶子节点上不存在的两个虚拟节点,它是红黑树旋转的假设性理论基础,默认是黑色的.

![image-20210904161046106](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210904161046106.png)

### 总结:

“有红必有黑,红红不相连”.上述5个约束条件保证了红黑树的新增、删除、查找的最坏运行时间为O(logn).如果一个树的左子节或右子节点不存在,则均认定为黑色.红黑树的任何旋转在3次之内均可完成.



## 红黑树与AVL树的比较

- 任意节点的黑深度(Block Depth)是指当前节点到NIL(树尾端)途径的黑色节点个数.由约束条件4 、5 ,可以推出对于任意高度的节点,它的黑深度都满足:`Block Depth >= height / 2`.
- 对于任意包含n个节点的红黑树而言,它的根节点高度**h<=log~2~(n+1)**
- 常规BST操作比如查找、删除、插入等,时间复杂度O(h),即取决于树的高度h.当树失衡时,时间复杂度将有可能恶化到O(n),即h=n.所以,当我们能保证树的高度始终保持在O(logn)时,便能保证所有操作的时间复杂度都能保持在O(logn)以内.
- 红黑树的平衡性并不如AVL树,它维持的是一种大致上的平衡,并不严格保证左右子树的高度差不超过1.
- 在相同节点树下,红黑树的高度可能更高,也就是说,平均查找次数会高于相同情况下的AVL树.
  - 在插入时,红黑树和AVL树都能在至多两次旋转内恢复平衡.
  - 在删除时,由于红黑树追求大致上的平衡,因此,红黑树能在至多三次旋转内恢复平衡,而追求绝对平衡的AVL树,则至多需要O(logn)次旋转.
- AVL树在插入与删除时,将向上回溯确定是否需要旋转,这个回溯的时间成本最差可能为O(logn),而红黑树每次向上回溯的步长为2,回溯成本低

**面对频繁的插入和删除,红黑树更合适;**

**面对低频修改、大量查询时,AVL树更合适.**







# TreeMap

![image-20210904165700982](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210904165700982.png)



TreeMap是按照Key的排序结果来组织内部结构的Map集合,它改变了Map类散乱无序的形象.

在TreeMap的接口继承树中,**SortedMap**和**NavigableMap**.

- SortedMap表示它的Key是有序不可重复的
  - 支持获取头尾Key-Value元素,或根据Key指定范围获取子集合.
  - 插入的Key必须实现Comparable或提供额外的比较器Comparator,所以Key不允许为null,但是Value可以;
- NavigableMap接口继承了SortedMap接口,根据指定的搜索条件返回最匹配的Key-Value元素.

不同与HashMap,TreeMap并非一定要覆写hashCode和equals方法来达到Key去重的目的.

```java
public class TreeMapRepeat {
    public static void main(String[] args) {
        //如果仅把此处的TreeMap换成HashMap，则size=1
        TreeMap map = new TreeMap();
        map.put(new Key(), "value one");
        map.put(new Key(), "value one");
        System.out.println(map.size());
    }
}

class Key implements Comparable<Key>{

    //返回负的常数，表示此对象永远小于输入的o对象，此处决定TreeMap的size=2
    @Override
    public int compareTo(Key o) {
        return -1;
    }

    //hash是相等的
    @Override
    public int hashCode() {
        return 1;
    }

    @Override
    public boolean equals(Object obj) {
        return true;
    }
}
```

>注意:
>
>HashMap是使用hashCode和equals实现去重的而TreeMap依靠Comparable或Comparator来实现Key的去重.
>
>如果没有覆盖正确的方法,那么TreeMap的最大特性将无法发挥出来,甚至在运行时会出现异常.

如果要用TreeMap对Key进行排序,调用如下方法:

```java
final int compare(Object k1, Object k2){
  return comparator == null ? ((Comparable<? super K>k1).compareTo((K)k2)) : comparator.compare((K)k1, (K)k2);
}
```

- 如果comparator不为null,优先使用比较器comparator的compare方法;
- 如果comparator为null,则使用Key实现的自然排序Comparable接口的compareTo方法.如果两者都无法满足,则抛出异常:

`Exception in thread "main" java.lang.ClassCastException: Key cannot be cast to java.base/java.lang.Comparable at java.base/java.utilTreeMap.compare(TreeMapjava:1291)`



基于红黑树实现的TreeMap提供了平均和最坏复杂度均为O(logn)的增删改查操作,并且实现了NavigableMap接口可,该集合最大的特点是Key的有序性.



### Entry<K key, V value>对象

```java
public class TreeMap<K, V> extends AbstractMap<K,V> implements NavigableMap<K,V>, Cloneable, java.io.Serializable{
  //比较器 
  private final Comparator<? super K> comparator;
  
  //根节点
  private transient Entry<K,V> root;
  //定义成为有字面含义的常量
  private static final boolean RED = false;
  private static final boolean BLACK = true;
  
  //TreeMap 的内部类,存储红黑树节点的载体类,在整个TreeMap中高频出现.
  static final class Entry<K,V> implements Map.Entry<K,V>{
    K key;
    V value;
    //指向左子树的引用
    Entry<K,V> left;
    //指向右子树的引用
    Entry<K,V> right;
    //指向父节点的引用
    Entry<K,V> parent;
    //节点颜色信息是红黑树的精髓,默认是黑色
    boolean color = BLACK;
  }
  ...
}
```



### TreeMap.put()

TreeMap通过put()和deleteEntry()实现红黑树的增加和删除节点操作.

插入节点之前,需要明确三个前提条件:

1. 需要调整的新节点总是红色的

2. 如果插入新节点的父节点是黑色的,无须调整.符合红黑树的5个约束条件

3. 如果插入新节点的父节点是红色的,因为红黑树规定不能出现相邻的两个红色节点,所以进入循环判断,或重新着色,或左右旋转,最终达到红黑树的五个约束条件,退出条件如下:

   ```java
   while(x != null && x != root && x.parent.color == RED){...}
   ```

   如果是根节点,则直接退出,设置为黑色即可;如果不是根节点,并且父节点为红色,会一直进行调整,直到退出循环.



#### 插入操作

- 按Key的对比往下遍历,大于比较节点值的向右走,小于比较节点值的向左走
- 先按照二叉查找树的特性进行操作,无须关心节点的颜色与树的平衡,后续会重新着色和旋转,保持红黑树的特性





#### put()方法分析

```java
public V put(K key, V value) {
  //t表示当前节点,这个很重要!!!!先把TreeMap的根节点root引用赋值给当前节点
        Entry<K,V> t = root;
  //如果当前节点为null,即是空树,新增的KV形成的节点就是根节点
        if (t == null) {
          //预检了Key是否可以比较
            compare(key, key); // type (and possibly null) check

          //使用KV构造出新的Entry对象,第三个参数是parent,根节点没有父节点
            root = new Entry<>(key, value, null);
            size = 1;
            modCount++;
            return null;
        }
  //cmp用来接收比较结果
        int cmp;
        Entry<K,V> parent;
        // 构造方法中置入的外部比较器
        Comparator<? super K> cpr = comparator;
  //重点步骤: 根据二叉查找树的特性,找到新节点插入的合适位置
        if (cpr != null) {
          //循环目标: 根据参数Key与当前节点的Key不断地进行对比
            do {
              //当前节点赋值给父节点,故从根节点开始遍历比较
                parent = t;
              //比较输入的参数Key和当前节点Key的大小
                cmp = cpr.compare(key, t.key);
              //参数的key更小,向左边走,把当前节点引用移动至它的左子节点上
                if (cmp < 0)
                    t = t.left;
              //参数的key更大,向右边走,把当前节点引用移动至它的右子节点上
                else if (cmp > 0)
                    t = t.right;
              //如果相等,则会残忍地覆盖当前节点的Value值,并返回更新前的值
                else
                    return t.setValue(value);
              //如果没有相等的Key,一直会遍历到NIL节点为止
            } while (t != null);
        }
  //在没有指定比较器的情况下,调用自然排序的Comparable比较
        else {
            if (key == null)
                throw new NullPointerException();
            @SuppressWarnings("unchecked")
                Comparable<? super K> k = (Comparable<? super K>) key;
            do {
                parent = t;
                cmp = k.compareTo(t.key);
                if (cmp < 0)
                    t = t.left;
                else if (cmp > 0)
                    t = t.right;
                else
                    return t.setValue(value);
            } while (t != null);
        }
  //创建Entry对象,并把parent置入参数
        Entry<K,V> e = new Entry<>(key, value, parent);
  //新节点找到自己的位置,原本以为可以安顿下来
        if (cmp < 0)
          //如果比较结果小于0,则称为parent的左孩子
            parent.left = e;
        else
          //如果比较结果大于0,则称为parent的右孩子
            parent.right = e;
  //还需要对这个新节点进行重新着色和旋转操作,以达到平衡
        fixAfterInsertion(e);
  //终于融入其中
        size++;
        modCount++;
  //成功插入新节点后,返回为null.
        return null;
    }
```

如果一个新节点在插入时能够运行到**fixAfterInsertion()**进行着色和旋转,说明:

1. 新节点加入之前是非空树
2. 新节点的Key与任何节点都不相同

**fixAfterInsertion()**是插入节点后的动作,和删除节点操作中的**fixAfterDeletion()**的原理基本相同.



#### fixAfterInsertion()

```java
 private void fixAfterInsertion(Entry<K,V> x) {
   //虽然内部类的Entry的属性color默认为黑色,但新节点一律先赋值为红色
        x.color = RED;

   //新节点是根节点或者其父节点为黑色,插入红色节点并不会破坏红黑树的性质,无须调整
   //x值的改变已用红色高亮显示,改变的过程是在不断地向上游遍历(或内部调整),直到父节点为黑色,或者到达根节点
        while (x != null && x != root && x.parent.color == RED) {
          //如果父节点是其父节点(爷爷)的左子节点
            if (parentOf(x) == leftOf(parentOf(parentOf(x)))) {
              //这时,得看爷爷的右子节点(简称为右叔)的脸色
                Entry<K,V> y = rightOf(parentOf(parentOf(x)));
              //如果右叔是红色,此时通过局部颜色调整,就可以使子树继续满足红黑树的性质
                if (colorOf(y) == RED) {			//(第1处)
                  //父亲置为黑色
                    setColor(parentOf(x), BLACK);
                  //右叔置为黑色
                    setColor(y, BLACK);
                  //爷爷置为红色
                    setColor(parentOf(parentOf(x)), RED);
                  //爷爷成为新的节点,进入到下一轮循环
                    x = parentOf(parentOf(x));
                  //如果右叔是黑色,则需要加入旋转
                } else {
                  //如果x是父亲的右子节点,先对父亲做一次左旋转操作
                  //转化x是父亲的左子节点的情形
                    if (x == rightOf(parentOf(x))) {
                      //对父亲做一次左旋转操作,红色的父亲会沉入其左侧位置
                      //将父亲赋值给X
                        x = parentOf(x);
                        rotateLeft(x);
                    }
                  //重新着色并对爷爷进行右旋操作
                    setColor(parentOf(x), BLACK);
                    setColor(parentOf(parentOf(x)), RED);
                    rotateRight(parentOf(parentOf(x)));
                }
              //与上方阴影代码相反,如果父亲是爷爷的右子节点
            } else {
              //则看左叔的脸色,原理相同
                Entry<K,V> y = leftOf(parentOf(parentOf(x)));
                if (colorOf(y) == RED) {
                    setColor(parentOf(x), BLACK);
                    setColor(y, BLACK);
                    setColor(parentOf(parentOf(x)), RED);
                    x = parentOf(parentOf(x));
                } else {
                    if (x == leftOf(parentOf(x))) {
                        x = parentOf(x);
                        rotateRight(x);
                    }
                    setColor(parentOf(x), BLACK);
                    setColor(parentOf(parentOf(x)), RED);
                    rotateLeft(parentOf(parentOf(x)));
                }
            }
        }
        root.color = BLACK;
    }
```

在第1处出现的colorOf()方法返回节点颜色.调整后的根节点必然是黑色的;叶子节点可能是黑色,也可能是红色的;叶子节点下挂的两个虚节点即NIL节点必然是黑色的,下方源码中的p==null时,返回为BLACK.

```java
private static <K,V> boolean colorOf(Entry<K,V> p){
  return (p == null ? BLACK : p.color);
}
```



### 左旋代码

输入参数为是去平衡的那棵子树的根节点

```java
private void rotateLeft(Entry<K,V) p){
  //如果参数节点不是NIL节点
  if(p != null){
    //获取p的右子节点r
    Entry<K,V> r = p.right;
    //将r的左子树设为p的右子树
    p.right = r.left;
    
    //若r的左子树不为空,则将p设置为r左子树的父亲
    if(r.lef != null)
      r.left.parent = p;
    //将p的父亲设置为r的父亲
    r.parent = p.parent;
    
    //无论如何,r都要在p父亲心目中替代p的位置
    if(p.parent == null)
      root = r;
    else if (p.parent.left == p)
      p.parent.left = r;
    else
      p.parent.right = r;
    
    //将p设置为r的左子树, 将r设置为p的父亲
    r.left = p;
    p.parent = r;
  }
}
```

#### 步骤

1. 获取p的右子节点r
2. r的左子树设为p的右子树
3. p的父亲设置为r的父亲
4. r在p的父亲心目中替代p
   - p父亲为null,则r为root
   - 如果p是p父亲的左子树,则r成为p父亲的左子树
   - 如果p是p父亲的右子树,则r成为p父亲的右子树
5. p成为r的左子树,r成为p的父亲





在树的演化过程中,插入节点的过程中,如果需要重新着色或旋转,存在三种情形:

1. 节点的父亲是红色,叔叔是红色,则重新着色
2. 节点的父亲是红色,叔叔是黑色的,而新节点是父亲的左节点: **进行右旋**
3. 节点的父亲是红色,叔叔是黑色的,而新节点是父亲的右节点: **进行左旋**



> 红黑树相比AVL树,任何不平衡都能在3次旋转之内调整完成.每次向上回溯的步长是2,对于频繁插入和删除的场景,红黑树的优势是非常明显的

ThreeMap是线程不安全的集合,不能在多线程之间进行共享数据的写操作.在多线程进行写操作时,需要添加互斥机制,或者把对象放在Collections.synchronizedMap(treeMap)中实现同步.







# HashMap

HashMap的**死链问题**及**扩容数据丢失问题**是慎用HashMap的两个主要原因

## 死链问题

#### 场景

某个应用在init()方法中初始化一个static的HashMap集合对象,从数据库提取数据到集合中.应用启动过程中仅单线程调用一次初始化方法,不应该有任何问题.但机缘巧合下,init()被执行了两次,启动失败、CPU使用率飙升,dump分析发现存在HashMap死链.

#### 解决方案

1. ConcurrentHashMap代替HashMap
2. 使用Collections.synchronizedMap(hashMap)包装成同步集合
3. 对init()进行同步操作.

选择第3种解决方案,毕竟启动时调用



#### 哈希类集合的基本存储

|  名称  |                     说明                      |
| :----: | :-------------------------------------------: |
| table  |            存储所有节点数据的数组             |
|  slot  |           哈希槽.即table[i]这个位置           |
| bucket | 哈希桶.即table[i]上所有元素形成的表或树的集合 |

![image-20210905142401979](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210905142401979.png)

- 黄色实线框即为**table数组**
- 红色箭头指向的即是**哈希槽**,仅是一个位置标识,对应于table数组下标
- 虚线所框的**哈希桶**是包含头节点在内,在哈希槽上形成的链表或树上的所有元素的集合.
- 黄色部分的数组长度就是**table.length**;
- 所有哈希桶的元素总和即为**HashMap的size.**



#### JDK7源码分析put()

```java
public V put(K key, V value){
  int hash = hash(key);
  int i = indexFor(hash, table.length);
  //此循环通过hashCode返回值找到对应的数组下标位置
  //如果equals结果为真,则覆盖原值,如果都为false,则添加元素
  for(Entry<K,V> e = table[i]; e != null; e = e.next){
    Object k;
    //如果Key是hash是相同的,那么在进行如下判断
    //Key是同一个对象或者equals返回为真,则覆盖原来的Value值
    if(e.hash == hash && ((k = e.key) == key || key.equals(k))){
      V oldValue = e.value;
      e.value = value;
      return oldValue;
    }
  }
  
  //还没有添加元素就进行modCount++,将为后续留下很多隐患
  modCount++;
  //添加元素,注意最后一个参数i是table数组的下标
  addEntry(hash,key,value,i);
  return nulll;
}

void addEntry(int hash, K key, V value, int bucketIndex){
  //如果元素的个数达到threshold的扩容阙值且数组下标位置已经存在元素,则进行扩容
  if((size >= threshold) && (null != table[bucketIndex])){
    //扩容2倍,size是实际存放元素的个数,而length是数组的容量大小(capacity)
    resize(2 * table.length);
    hash = (null != key) ? hash(key) : 0;
    bucketIndex = indexFor(hash, table.length);
  }
  
  createEntry(hash, key, value, bucketIndex);
}

//插入元素时,应插入在头部,而不是尾部
void createEntry(int hash,, K key, V value, int bucketIndex){
  ///不管原来的数组对应的下标元素是否为null,都作为Entry的bucketIndex的next值
  Entry<K,V> e = table[bucketIndex];
  //即使原来是链表,也把整条链都挂在新插入的节点上.
  table[bucketIndex] = new Entry<>(hash, key, value, e);
  size++;
}
```



#### 死链的生成,需要明确三点

```java
while(null != e){
  Entry<K,V> next = e.next;
  e.next = newTable[5883];
  newTable[5883] = e;
  e = next;
}
```

1. 原先没有死链的同一个slot上节点遍历一定能够按顺序走完.因为e和next都说线程内的局部变量,是绝对不会互相干扰的,所以while循环在此处生成死链的过程中是会正常退出的
2. table数组是各线程都可以共享修改的对象
3. put()、get()和transfer()三种操作在运行到此拥有死链的slot上,CPU使用率都会飙升.



两个线程A和B,执行transfer方法,虽然newTable是局部变量;但是原先table中的Entry链表是共享的.产生问题的根本根源是Entry的next被修改.这可能导致:

- 对象丢失
- 两个对象互链
- 对象自己互链

形成环路的原因是两个线程都执行完第一个节点的遍历操作后,到第二个节点时,产生互链.



## 扩容数据丢失问题

### 扩容

| 名称     | 说明                                                         |
| -------- | ------------------------------------------------------------ |
| length   | table数组的长度                                              |
| size     | 成功通过put方法添加到HashMap中的所有元素的个数               |
| hashCode | Object.hashCode()返回的int值,尽可能地离散均匀分布            |
| hash     | Object.hashCode()与当前集合的table.length进行位运算的结果,以确定哈希槽的位置. |

> 哈希碰撞的概率取决于hashCode计算方式和空间容量大小
>
> 负载因子就是用以权衡资源利用率与分配空间的系数,默认的负载因子是0.75
>
> HashMap中,每次进行resize操作都会将容量扩充为原来的2倍



#### resize()

```java
public void resize(int newCapacity){ //传入新的容量
        Entry[] oldTable = table;
        int odlCapacity = oldTable.length;
        if(odlCapacity == MAXIMUM_CAPACITY){  ///扩容前的数组大小如果已经达到最大 (2^30)了
            threshold = Integer.MAX_VALUE;  //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了
            return;
        }
        Entry[] newTable = new Entry[newCapacity];
        transfer(newTable);   //将数据转移到新的Entry数组里
        table = newTable;    //HashMap的table属性引用新的 Entry数组
        threshold = (int)(newCapacity * loadFactory);//修改阈值


    }
//使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。
    void transfer(Entry[] newTable){
        Entry[] src = table; //src引用了旧的Entry数组
        int newCapacity = newTable.length;
        for (int i = 0; i < src.length; i++) { //遍历旧的Entry数组
                Entry<K,V> e = src[i];      ///取得旧Entry数组的每个元素
                if(e != null){
                    src[i] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象）
                    do{
                        Entry<K,V> next = e.next;
                        int j = indexFor(e.hash,newCapacity);//重新计算每个元素在数 组中的位置
                        e.next = newTable[j];  
                        newTable[j] = e;  //将元素放在数组上
                        e = next;//访问下一个Entry链上的元素
                    }while (e != null);
                }
        }
    }
```

transfer()数据迁移方法在数组非常大时会非常消耗资源.当前线程迁移过程中,其他线程新增的元素有可能落在已经遍历过的哈希槽上;在遍历完成之后,table数组引用指向了newTable,这时新增元素就会丢失,被无情地垃圾回收.



如果多个线程同时执行resize,每个线程又都会new Entry[newCapacity],这时线程内的局部数组对象,线程之间是不可见的.迁移完成后,resize的线程会赋值给table线程共享变量,从而覆盖其他线程的操作,因此在“新表”中进行插入操作的对象会被无情地丢弃.



##### 新增对象丢失原因

- 并发赋值时被覆盖
- 已遍历区间新增元素会丢失
- “新表”被覆盖
- 迁移丢失.在迁移过程中,有并发时,next被提前置为null.

 

JDK7的扩容条件是`(size >= threshold)&&(null != table[bucketIndex])`,即达到阈值,并且当前需要存放对象的slot上已经有值.从代码上看,是先扩容,然后进行新增元素操作,而JDK8是增加元素之后扩容.

JDK8的HashMap改进了这种从头节点就开始操作数据迁移的方法,采用对原先链表的头尾节点引用,保证“有序性”.对于HashMap的分析仅限于死链和对象丢失分析,是希望在使用JDK8之前的版本时,规避这样的风险或直接使用ConcurrentHashMap



# ConcurrentHashMap

使用了大量的lock-free技术来减轻因锁的竞争而对性能造成的影响.

> CAS(Compare And Swap), 它是解决轻微冲突的多线程并发场景下使用锁造成性能损耗的一种机制.
>
> 每一次执行都必须进行加速和解锁的成本是比较高的,在并发度比较低的情况下,这种时间成本消耗是比较奢侈.
>
> CAS就是先比较,如果不符合预期,则进行重试.

CAS操作包含三个操作要素:

- 内存位置
- 预期原值(假设A)
- 新值(假设B)

如果内存位置的值与预期原值相等,则处理器将该位置值更新为新值.如果不相等,则获取当前值,然后进行不断的轮询操作,直到成功或达到某个阈值退出.典型代码如下:

```java
public final int getAndincrement(){
  for(;;){
    int current = get();
    int next = current + 1;
    if(compareAndSet(current, next)){
      return current;
    }
  }
}
```



## 更迭

- JDK8之前,采用分段锁的设计理念.
  - 分段锁是由内部类Segment实现的,它继承于ReentrantLock,用来管理它辖区的各个HashEntry.
  - ConcurrentHashMap被Segment分成了很多小区,Segment就相当于小区保安,HashEntry列表相当于小区业主,小区保安通过加锁的方式,保证每个Segment内都不发生冲突
- JDK11对JDK7的版本进行了三点改造
  - 取消分段锁机制,进一步降低冲突概率
  - 引入红黑树结构.同一个哈希槽上的元素超过一定阈值(8),单向链表改为红黑树结构
  - 使用了更加优化的方式统计集合内的元素数量.
    - Map原有的size()方法最大只能表示到2^31^-1
    - 额外提供了mappingCount()方法,用来返回集合内元素的数量,最大可以表示到2^63^-1.
    - 元素总数更新时,使用了CAS和多种优化以提高并发能力

```java
//默认为null,ConcurrentHashMap存放数据的地方,扩容时大小总是2的幂次方
//初始化发生在第一次插入操作,数组默认初始化大小为16
transient volatile Node<K,V>[] table;

//默认为null,扩容时新生成的数组,其大小为原数组的两倍
private transient volatile Node<K, V>[] nextTable;

//存储单个KV数据节点.内部有key, value, hash, next指向下一个节点
//它有4个在ConcurrentHashMap类内部定义的子类:
//TreeBin、TreeNode、ForwardingNode、ReservationNode
//前3个子类都重写了查找元素的重要方法find()
static class Node<K,V> implements Map.Entry<K,V>{...}

//它并不存储实际数据,维护对桶内红黑树的读写锁,存储对红黑树节点的引用
static final class TreeBin<K,V> extends Node<K,V> {...}

//在红黑树结构中,实际存储数据的节点
static final class TreeNode<K,V> extends Node<K,V> {...}

//扩容转发节点,放置此节点后,外部对原有哈希槽的操作会转发到nextTable上
static final class ForwardingNode<K, V> extends Node<K, V> {...}

//占位加锁节点. 执行某些方法时,对其加锁,如computeIfAbsent等
static final class ReservationNode<K, V> extends Node<K, V> {...}

//默认为0,重要属性,用来控制table的初始化和扩容操作
//sizeCtl=-1,表示正在初始化中
//sizeCtl=-n, 表示(n-1)个线程正在进行扩容中
//sizeCtl>0, 初始化或扩容中需要使用的容量
//sizeCtl=0, 默认值,使用默认容量进行初始化
private transient volatile int sizeCtl;

//集合size小于64,无论如何,都不会使用红黑树结构
//转换为红黑树还有一个条件是TREEIFY_THRESHOLD
static final int MIN_TREEIFY_CAPACITY = 64;

//同一个哈希桶内存储的元素个数超过此阈值时
//则存储结构由链表转为红黑树
static final int TREEIFY_THRSHOLD = 9;

//同一个哈希桶内存储的元素个数小于等于此阈值时
//从红黑树回退至链表结构,因为元素个数较少时,链表更快
static final int UNTREEIFY_THRESHOLD = 6;
```

![image-20210905215053392](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210905215053392.png)

- table的长度为64,数据存储结构分为:链表和红黑树.
- 当某个槽内的元素个数增加到超过8个且table的容量大于或等于64时,由链表转为红黑树(链表转红黑树的过程就是给定顺序的元素构造成一棵红黑树的过程)
- 当某个槽内的元素个数减少到6个时,由红黑树重新转回链表

>当table的容量小于64时,只会扩容,并不会把链表转为红黑树
>
>在转换过程中,使用同步块锁住当前槽的首元素,防止其他进程对当前槽进行增删改查操作,转换完成后利用CAS替换原有链表
>
>因为TreeNode节点也存储量next引用,所以红黑树转链表的操作就变的简单,只需从TreeBin的first元素开始遍历所有的节点,并把节点从TreeNode类型转化为Node类型即可,当构造好新的链表之后,会同样利用CAS替换原有红黑树.



#### 链表转红黑树流程图

![image-20210905220757147](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210905220757147.png)

​																		**ConcurrentHashMap元素插入流程图**

触发上述存储结构转化最主要的操作时增加元素,即put()方法.基本思想与HashMap一致,区别就是增加了锁的处理.

![image-20210905221951539](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210905221951539.png)

​																		**ConcurrentHashMap元素扩容流程图**



##### **ForwardingNode**

- ForwardingNode在table扩容时使用,内部记录了扩容后的table,即nextTable.
- 当table需要进行扩容时,依次遍历当前table中的每一个槽,如果不为null,则需要把其中所有的元素根据hash值放入扩容后的nextTable中,而原table的槽内会放置一个ForwardingNode节点
- 此节点会把find()请求转发到扩容后的nextTable上
- 而执行put()方法的线程如果碰到此节点,也会协助进行迁移.



##### ReservationNode

- ReservationNode在computeIfAbsent()及其相关方法中作为一个预留节点使用.
- computeIfAbsent()方法会先判断相应的Key值是否已存在,如果不存在,则调用由用户实现的自定义方法来生成Value值,组成KV键值对,随后插入此哈希集合中.
- 在并发场景下,在从得知Key不存在到插入哈希集合的时间间隔内,为了防止哈希槽被其他线程抢占,当前线程会使用一个ReservationNode节点放到槽中并加锁,从而保证了线程的安全性.





#### size()

无论JDK7还是JDK8,ConcurrentHashMap的size方法都只能返回一个大概数量无法做到100%的精确,因为已经统计过的哈希槽在size返回最终结果前有可能又出现了变化,从而导致返回大小与实际大小存在些许差异.

JDK8对ConcurrentHashMap对元素总数的计算又做了进一步的优化,具体表现在: 在put()、remove()和size()方法中,涉及元素总数的更新和计算,都彻底避免了锁的使用,取而代之的是众多的CAS操作.



JDK7版本中的put方法和remove方法,对呀segment内部元素和计数器的更新,全部处于锁的保护下.如Segment.put()方法的第一行:

```java
//经过这一行代码,能够保证当前线程取得改Segment上的锁,随后可以大胆地更新元素和内部的计数器
HashEntry<K> node = tryLock() ? null : scanAndLockForPut(key, hash, value);
```

![image-20210905230524315](/Users/lushengyang/Desktop/LSY/StudeyNotes/image/image-20210905230524315.png)

​															**JDK7版本的ConcurrentHashMap获取集合大小流程图**

只有当经过了3次计算(2次对比)后,发现每次统计时哈希都有结构性的变化,才会把所有Segment都加上锁;当自己统计完成后,才会把锁释放掉,再运行其他线程修改哈希中的元素



JDK8的ConcurrentHashMap在put方法中,对于哈希元素总数的更新,是置于对某个槽的锁之外的,主要会用到的属性如下:

```java
//记录了元素总数值,主要用在无竞争状态下
//在总数更新后,通过CAS方式直接更新这个值
private transient volatile long baseCount;
//一个计数器单元,维护了一个value值
static final class CounterCell {...}
//在竞争激烈的状态下启用,线程会把总数更新情况存放到该结构内
//当竞争进一步加剧时,会通过扩容减少竞争
private transient volatile CounterCell[] counterCells;
```

借助baseCount和counterCells两个属性,并配合多次使用CAS方法,JDK中的ConcurrentHashMap避免了锁的使用.

思路:

- 当并发量较小时,优先使用CAS的方式直接更新baseCount
- 当更新baseCount冲突,则会认为进入到比较激烈的竞争状态,通过启用counterCells减少竞争,通过CAS的方式把总数更新情况记录在counterCells对应的位置上.
- 当counterCells处在扩容期间时,会尝试更新baseCount值.

对于元素总数的统计,只需要让baseCount加上各counterCells内的数据,就可以得出哈希内的元素总数,整个过程完全不需要借助锁.







# 图

图是一种复杂的非线性结构。

在线性结构中，数据元素之间满足唯一的线性关系，每个数据元素(除第一个和最后一个外)只有一个直接前趋和一个直接后继；

在树形结构中，数据元素之间有着明显的层次关系，并且每个数据元素只与上一层中的一个元素(双亲节点)及下一层的多个元素(孩子节点)相关；

而在图形结构中，节点之间的关系是任意的，图中任意两个数据元素之间都有可能相关。

图G由两个集合**V(顶点Vertex)**和**E(边Edge)**组成，定义为**G=(V，E)**

## 无向图

对于一个图，若每条边都是没有方向的，则称该图为无向图

![image-20210906013443411](/Users/lushengyang/Desktop/LSY/StudeyNotes/interview/image-20210906013443411.png)

(V~i~,V~j~)和(V~j~,V~i~)表示的是同一条边

> 无向图是用小括号,有向图是用尖括号

无向图的顶点集和边集:

- V(G)={V~1~,V~2~,V~3~,V~4~,V~5~}
- E(G)={ (V~1~,V~2~), (V~1~,V~4~), (V~2~,V~3~), (V~2~,V~5~), (V~3~,V~4~), (V~3~,V~5~), (V~4~, V~5~) }







## 有向图

对于一个图G，若每条边都是有方向的，则称该图为有向图

![image-20210906014137890](/Users/lushengyang/Desktop/LSY/StudeyNotes/interview/image-20210906014137890.png)

<V~i~，V~j~>和<V~j~，V~i~>是两条不同的有向边。注意，有向边又称为弧。

有向图的**顶点集**和**边集**分别表示为：

- V(G)={V~1~，V~2~，V~3~}
- E(G)={<V~1~，V~2~>，<V~2~，V~3~>，<V~3~，V~1~>，<V~1~，V~3~>}



## 无向完全图和有向完全图

将具有`n(n-1)/2`条边的无向图称为无向完全图。同理，将具有`n(n-1)`条边的有向图称为有向完全图。



### 顶点的度

对于无向图，顶点的度表示以该顶点作为一个端点的边的数目。比如，无向图中顶点V~3~的度D(V~3~)=3

对于有向图，顶点的度分为入度和出度。入度表示以该顶点为终点的入边数目，出度是以该顶点为起点的出边数目，该顶点的度等于其入度和出度之和。比如，顶点V1的入度ID(V~1~)=1，出度OD(V~1~)=2，所以D(V~1~)=ID(V~1~)+OD(V~1~)=1+2=3

记住，不管是无向图还是有向图，顶点数n，边数e和顶点的度数有如下关系：

![image-20210906014748903](/Users/lushengyang/Desktop/LSY/StudeyNotes/interview/image-20210906014748903.png)

以有向图为例,由公式可得到图G的边数e=(D(V~1~)+D(V~2~)+D(V~3~))/2=(3+2+3)/2=4





### 路径，路径长度和回路

- 路径，比如在无向图G中，存在一个顶点序列V~p~,V~i1~,V~i2~,V~i3~…，V~im~，V~q~，使得(V~p~,V~i1~)，(V~i1~,V~i2~)，…,(V~im~,V~q~)均属于边集E(G)，则称顶点V~p~到V~q~存在一条路径。
- 路径长度，是指一条路径上经过的边的数量。
- 回路，指一条路径的起点和终点为同一个顶点。



## 连通图

连通图是指图G中任意两个顶点V~i~和V~j~都连通，则称为连通图

![image-20210906015530780](/Users/lushengyang/Desktop/LSY/StudeyNotes/interview/image-20210906015530780.png)

​																	**非连通图(无向图)**

因为V~5~和V~6~是单独的，所以是非连通图。



## 网

带”权值”的连通图称为网。

![image-20210906015921628](/Users/lushengyang/Desktop/LSY/StudeyNotes/interview/image-20210906015921628.png)





