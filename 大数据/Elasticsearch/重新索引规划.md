---
sedb重新索引规划
---

[toc]

----



## 重新索引预估

![image-20220114103345228](http://qiliu.luxiaobai.cn/img/image-20220114103345228.png)

![image-20220114103359845](http://qiliu.luxiaobai.cn/img/image-20220114103359845.png)

`node-1`分片数

![image-20220114103511214](http://qiliu.luxiaobai.cn/img/image-20220114103511214.png)

`node-2`分片数

![image-20220114103554304](http://qiliu.luxiaobai.cn/img/image-20220114103554304.png)

执行重新索引

```
PUT http://127.0.0.1:9200/txt_number3
{
    "settings": {
        "number_of_shards": 30,
        "number_of_replicas": 0
    },
    "mappings": {
        "properties": {
            "number": {
                "type": "text"
            }
        }
    }
}

POST http://127.0.0.1:9200/_reindex
{ 
  "source": {
    "index": "txt_number"
    "size": 10000
    },
    "dest": { 
      "index": "txt_number3" 
    } 
}

```

**根据本机索引规划预估：在本机双节点集群下重新索引的分片数据会在两个节点重新复制。对原先分片数据重新复制一份，因此在进行重新索引时需要预估当前节点的磁盘容量是否足够。**

> 例如双节点集群，他们某个索引有**50**个分片，容量为**1.4**T，每个节点占据**25**个分片，即每个节点占据**700G**容量。而每个节点所在服务器的磁盘容量为**1.8**T。则再重新索引时，每个节点都需要复制之前索引的总容量的一半即**700G**。则最后每个节点所在服务器所用的磁盘容量为`1.4T`.所以==在进行重新索引时请计算好节点所在磁盘的容量，默认磁盘使用率达到`85%`则不会进行新分片分配，磁盘使用率超过`90%`ES会尝试将对应节点中的分片迁移到其他磁盘使用率比较低的数据节点中，磁盘使用率超过`95%`系统会对ES集群中的每个索引强制设置`read_only_allow_delete`属性，此时索引将无法写入数据，只能读取和删除对应索引==.在进行重新索引之前规划好磁盘容量，即可以进行动态的根据API来调整磁盘使用率。



在创建新索引时，设置`refresh_intervals = -1, number_of_replicas = 0`可以有效提高重建速度（==重新索引完成后要恢复，默认是1s==）

由于在数据量大的情况下，进行重建索引，可以在请求参数中上`wait_for_completion=false`,这也`reindex`将直接返回`taskID`

```shell
POST _reindex?wait_for_completion=false
{
	"source":{
		"index": "old_index"
		"size": 10000
	},
	"dest": {
		"index": "new_index"
	}
}
```

在进行重建索引中，可以使用`GET _tasks/{taskID}`查看重建进程，其中包含耗时，剩余doc数量等信息

如果发现错误，还可以使用`PUT _tasks/{taskID}/cancel`接口放弃任务，从头在来。





## sedb重新索引预估

#### 操作步骤

1、创建新的索引库sedb,设置主分片、副本、refresh `PUT /"refresh_intervals": -1`

```shell
PUT sedb_20220114
{
  "settings": {
    "number_of_shards" : "100",
    "number_of_replicas" : "0",
    
    "analysis": {
      "filter": {
        "email": {
          "type": "pattern_capture",
          "preserve_original": true,
          "patterns": [
            "([^@]+)",
            "(\\p{L}+)",
            "(\\d+)",
            "@(.+)",
            "([^-@]+)"
          ]
        },
        "suf_email" : {
              "type" : "pattern_capture",
              "preserve_original" : "true",
              "patterns" : [
                "@(\\w+)",
                "@(.+)",
                "@(\\w+\\.\\w+)",
                "@(\\w+\\.\\w+.\\w+)"
              ]
            },
          "pre_email" : {
            "type" : "pattern_capture",
            "preserve_original" : "true",
            "patterns" : [
              "(.+)@"
            ]
          }
      },
      "analyzer": {
        "email": {
          "tokenizer": "uax_url_email",
          "filter": [
            "email",
            "lowercase",
            "unique"
          ]
        },
        "suf_email" : {
           "tokenizer" : "uax_url_email",
           "filter" : [
              "suf_email",
              "lowercase",
              "unique"
          ]
        },
        "pre_email" : {
          "tokenizer" : "uax_url_email",
          "filter" : [
            "pre_email",
            "lowercase",
            "unique"
          ]
      }
      }
    }
  },
  "mappings": {
      "properties": {
        "email": {
          "type": "text",
          "analyzer": "email",
          "search_analyzer": "email",
           "copy_to" : [
            "pre_email",
            "suf_email"
          ]
        },
        "pre_email" : {
            "type" : "text",
            "analyzer" : "pre_email",
            "search_analyzer": "pre_email"
        },
        "suf_email" : {
          "type" : "text",
          "analyzer" : "suf_email",
          "search_analyzer": "suf_email"
        },
        "username": {
          "type": "text",
          "analyzer": "email"
        },
        "password_hash": {
           "type": "text"
        },
        "password": {
          "type": "text"
        },
        "info_str": {
          "type": "text",
          "analyzer": "ik_max_word",
          "search_analyzer": "ik_max_word"
        },
        "db":{
          "properties":{
          "fileTime": {"type": "date"},
          "sedbName": {"type": "text"}
          }
        }
      }
  }
}
```

2、数据拷贝

```shell
POST _reindex?wait_for_completion=false&slices=auto&refresh
{
    "source": {
        "index": "sedb",
        "size": 10000
    },
    "dest": {
        "index": "sedb_20220114"
    }
}
```

3、查看重建进程`GET _tasks/${taskID}`

4、放弃重建索引任务`PUT _tasks/${taskID}/cancel`

5、多索引任务

1. 设置`sedb`查询别名`PUT sedb/_alias/sedb_search`

2. 新增多索引，mapping配置如sedb相同，可以相应修改mapping的一些配置。`PUT sedb_2022114_index`

3. 多索引设置

   ```shell
   POST _aliases
   {
       "actions": [
           {
               "add": {
                   "index": "sedb_2022114_index",
                   "alias": "sedb_search"
               }
           },
           {
               "remove": {
                   "index": "sedb",
                   "alias": "sedb_index"
               }
           },
           {
               "add": {
                   "index": "sedb_2022114_index",
                   "alias": "sedb_index"
               }
           }
       ]
   }
   ```

4. 恢复`refresh_interval`间隔，和设置副本数

   ```shell
   PUT sedb/_settings
   {
   	"refresh_interval": "30s", //如果对实时要求不是很高可以设置为30
   	"number_of_replicas": 1
   }
   ```

   

#### 重新索引后，文档数量不一致解决方案

> op_type 对于文档数量没有同步成功下的使用

当重新索引任务结束后， 文档数量不一致可以进行在重新索引的方法,具体操作如下：

```
http://192.168.3.147:9200/_reindex?wait_for_completion=false&slices=auto&refresh
{
    "conflicts": "proceed",
    "source": {
        "index": "sedb",
        "size": "5000"
    },
    "dest": {
        "index": "sedb_20220117",
        "op_type": "create"
    }
}
```

参数介绍：[more](https://www.elastic.co/guide/en/elasticsearch/reference/7.3/docs-reindex.html)

-  **op_type**: `create `将导致 `_reindex` 仅在目标索引中创建缺少的文档。 所有现有文档都会导致版本冲突。默认参数是:`index`
- **conflicts**（可选，枚举）：设置为`proceed`即使存在冲突也继续重新索引。默认为`abort`.



## 优化方案

- **jvm**配置 `-Xms31G -Xmx31G`,官网推荐不要超过物理内存的50%，一半交给ES服务，一半交给Lucen底层库。JVM并非越大越好。[官方详情](https://www.elastic.co/guide/cn/elasticsearch/guide/current/heap-sizing.html#compressed_oops)

- 当节点数>=3时，增加副本数`"number_of_replicas": 1`,设置为1即可，除非数据非常重要，否则浪费磁盘空间。一般情况设置1，副本既可以增加ES的搜索量也可以增加吞吐量，同时可以防止单点故障进行数据备份。

- 禁用SWAP，，一旦允许内存与磁盘的交换，会引起致命的性能问题。可以通过在 **elasticsearch.yml** 中 `bootstrap.memory_lock: true`，以保持 JVM 锁定内存，保证 ES 的性能。[官方详情](https://www.elastic.co/guide/cn/elasticsearch/guide/current/heap-sizing.html#_swapping_%E6%98%AF%E6%80%A7%E8%83%BD%E7%9A%84%E5%9D%9F%E5%A2%93)

- 进行段合并操作 `POST sedb/_forcemerge?max_num_segments=1`

- 禁用`dynamic` 关闭动态字段映射  ` "dynamic": false`

- GC设置，ES的老版本默认设置为：`Concurrent-Mark and Sweep(CMS) `   ==该设置仅供参考,官方的建议是尽量不要动这个配置==。

  ```shell
  vim jvm.options
  ##将这几行
  -XX:+UseConcMarkSweepGC
  -XX:CMSInitiatingOccupancyFraction=75
  -XX:+UseCMSInitiatingOccupancyOnly
  ###改为如下
  -XX:+UseG1GC
  -XX:MaxGCPauseMillis=50
  ```

